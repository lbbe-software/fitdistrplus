<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Which optimization algorithm to choose? • fitdistrplus</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Which optimization algorithm to choose?">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">fitdistrplus</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.2-4</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/fitdistrplus_vignette.html">Overview of the fitdistrplus package</a></li>
    <li><a class="dropdown-item" href="../articles/FAQ.html">Frequently Asked Questions</a></li>
    <li><a class="dropdown-item" href="../articles/Optimalgo.html">Which optimization algorithm to choose?</a></li>
    <li><a class="dropdown-item" href="../articles/starting-values.html">Starting values used in fitdistrplus</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/lbbe-software/fitdistrplus/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Which optimization algorithm to choose?</h1>
                        <h4 data-toc-skip class="author">Marie Laure
Delignette Muller, Christophe Dutang</h4>
            
            <h4 data-toc-skip class="date">2025-11-20</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/lbbe-software/fitdistrplus/blob/master/vignettes/Optimalgo.Rmd" class="external-link"><code>vignettes/Optimalgo.Rmd</code></a></small>
      <div class="d-none name"><code>Optimalgo.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="quick-overview-of-main-optimization-methods">1. Quick overview of main optimization methods<a class="anchor" aria-label="anchor" href="#quick-overview-of-main-optimization-methods"></a>
</h2>
<p>We present very quickly the main optimization methods. Please refer
to <strong>Numerical Optimization (Nocedal &amp; Wright, 2006)</strong>
or <strong>Numerical Optimization: theoretical and practical aspects
(Bonnans, Gilbert, Lemarechal &amp; Sagastizabal, 2006)</strong> for a
good introduction. We consider the following problem
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>min</mo><mi>x</mi></msub><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\min_x f(x)</annotation></semantics></math>
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>∈</mo><msup><mi>ℝ</mi><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">x\in\mathbb{R}^n</annotation></semantics></math>.</p>
<div class="section level3">
<h3 id="derivative-free-optimization-methods">1.1. Derivative-free optimization methods<a class="anchor" aria-label="anchor" href="#derivative-free-optimization-methods"></a>
</h3>
<p>The Nelder-Mead method is one of the most well known derivative-free
methods that use only values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>
to search for the minimum. It consists in building a simplex of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n+1</annotation></semantics></math>
points and moving/shrinking this simplex into the good direction.</p>
<ol style="list-style-type: decimal">
<li>set initial points
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_1, \dots, x_{n+1}</annotation></semantics></math>.</li>
<li>order points such that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>≤</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>≤</mo><mi>…</mi><mo>≤</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(x_1)\leq f(x_2)\leq\dots\leq f(x_{n+1})</annotation></semantics></math>.</li>
<li>compute
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>o</mi></msub><annotation encoding="application/x-tex">x_o</annotation></semantics></math>
as the centroid of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">x_1, \dots, x_{n}</annotation></semantics></math>.</li>
<li>Reflection:
<ul>
<li>compute the reflected point
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>r</mi></msub><mo>=</mo><msub><mi>x</mi><mi>o</mi></msub><mo>+</mo><mi>α</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>o</mi></msub><mo>−</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">x_r = x_o + \alpha(x_o-x_{n+1})</annotation></semantics></math>.</li>
<li>
<strong>if</strong>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>≤</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>r</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>&lt;</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(x_1)\leq f(x_r)&lt;f(x_n)</annotation></semantics></math>,
then replace
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">x_{n+1}</annotation></semantics></math>
by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>r</mi></msub><annotation encoding="application/x-tex">x_r</annotation></semantics></math>,
go to step 2.</li>
<li>
<strong>else</strong> go step 5.</li>
</ul>
</li>
<li>Expansion:
<ul>
<li>
<strong>if</strong>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>r</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>&lt;</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(x_r)&lt;f(x_1)</annotation></semantics></math>,
then compute the expansion point
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>e</mi></msub><mo>=</mo><msub><mi>x</mi><mi>o</mi></msub><mo>+</mo><mi>γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>o</mi></msub><mo>−</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">x_e= x_o+\gamma(x_o-x_{n+1})</annotation></semantics></math>.</li>
<li>
<strong>if</strong>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>e</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>&lt;</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>r</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(x_e) &lt;f(x_r)</annotation></semantics></math>,
then replace
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">x_{n+1}</annotation></semantics></math>
by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>e</mi></msub><annotation encoding="application/x-tex">x_e</annotation></semantics></math>,
go to step 2.</li>
<li>
<strong>else</strong>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">x_{n+1}</annotation></semantics></math>
by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>r</mi></msub><annotation encoding="application/x-tex">x_r</annotation></semantics></math>,
go to step 2.</li>
<li>
<strong>else</strong> go to step 6.</li>
</ul>
</li>
<li>Contraction:
<ul>
<li>compute the contracted point
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>c</mi></msub><mo>=</mo><msub><mi>x</mi><mi>o</mi></msub><mo>+</mo><mi>β</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>o</mi></msub><mo>−</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">x_c = x_o + \beta(x_o-x_{n+1})</annotation></semantics></math>.</li>
<li>
<strong>if</strong>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>c</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>&lt;</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(x_c)&lt;f(x_{n+1})</annotation></semantics></math>,
then replace
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">x_{n+1}</annotation></semantics></math>
by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>c</mi></msub><annotation encoding="application/x-tex">x_c</annotation></semantics></math>,
go to step 2.<br>
</li>
<li>
<strong>else</strong> go step 7.</li>
</ul>
</li>
<li>Reduction:
<ul>
<li>for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>=</mo><mn>2</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">i=2,\dots, n+1</annotation></semantics></math>,
compute
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>=</mo><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mi>σ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">x_i = x_1+\sigma(x_i-x_{1})</annotation></semantics></math>.</li>
</ul>
</li>
</ol>
<p>The Nelder-Mead method is available in <code>optim</code>. By
default, in <code>optim</code>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\alpha=1</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mo>=</mo><mn>1</mn><mi>/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">\beta=1/2</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">\gamma=2</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi><mo>=</mo><mn>1</mn><mi>/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">\sigma=1/2</annotation></semantics></math>.</p>
</div>
<div class="section level3">
<h3 id="hessian-free-optimization-methods">1.2. Hessian-free optimization methods<a class="anchor" aria-label="anchor" href="#hessian-free-optimization-methods"></a>
</h3>
<p>For smooth non-linear function, the following method is generally
used: a local method combined with line search work on the scheme
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mi>k</mi></msub><mo>+</mo><msub><mi>t</mi><mi>k</mi></msub><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">x_{k+1} =x_k + t_k d_{k}</annotation></semantics></math>,
where the local method will specify the direction
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>d</mi><mi>k</mi></msub><annotation encoding="application/x-tex">d_k</annotation></semantics></math>
and the line search will specify the step size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>k</mi></msub><mo>∈</mo><mi>ℝ</mi></mrow><annotation encoding="application/x-tex">t_k \in \mathbb{R}</annotation></semantics></math>.</p>
<div class="section level4">
<h4 id="computing-the-direction-d_k">1.2.1. Computing the direction
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>d</mi><mi>k</mi></msub><annotation encoding="application/x-tex">d_k</annotation></semantics></math><a class="anchor" aria-label="anchor" href="#computing-the-direction-d_k"></a>
</h4>
<p>A desirable property for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>d</mi><mi>k</mi></msub><annotation encoding="application/x-tex">d_k</annotation></semantics></math>
is that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>d</mi><mi>k</mi></msub><annotation encoding="application/x-tex">d_k</annotation></semantics></math>
ensures a descent
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>&lt;</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(x_{k+1}) &lt; f(x_{k})</annotation></semantics></math>.
Newton methods are such that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>d</mi><mi>k</mi></msub><annotation encoding="application/x-tex">d_k</annotation></semantics></math>
minimizes a local quadratic approximation of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>
based on a Taylor expansion, that is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>f</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>d</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>g</mi><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>T</mi></msup><mi>d</mi><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msup><mi>d</mi><mi>T</mi></msup><mi>H</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">q_f(d) = f(x_k) + g(x_k)^Td +\frac{1}{2} d^T H(x_k) d</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
denotes the gradient and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>H</mi><annotation encoding="application/x-tex">H</annotation></semantics></math>
denotes the Hessian.</p>
<p>The consists in using the exact solution of local minimization
problem
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><mo>−</mo><mi>H</mi><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">d_k = - H(x_k)^{-1} g(x_k)</annotation></semantics></math>.<br>
In practice, other methods are preferred (at least to ensure positive
definiteness). The method approximates the Hessian by a matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>H</mi><mi>k</mi></msub><annotation encoding="application/x-tex">H_k</annotation></semantics></math>
as a function of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>H</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">H_{k-1}</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>k</mi></msub><annotation encoding="application/x-tex">x_k</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(x_k)</annotation></semantics></math>
and then
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>d</mi><mi>k</mi></msub><annotation encoding="application/x-tex">d_k</annotation></semantics></math>
solves the system
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mi>k</mi></msub><mi>d</mi><mo>=</mo><mo>−</mo><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">H_k d = -  g(x_k)</annotation></semantics></math>.
Some implementation may also directly approximate the inverse of the
Hessian
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mi>k</mi></msub><annotation encoding="application/x-tex">W_k</annotation></semantics></math>
in order to compute
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><mo>−</mo><msub><mi>W</mi><mi>k</mi></msub><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">d_k = -W_k g(x_k)</annotation></semantics></math>.
Using the Sherman-Morrison-Woodbury formula, we can switch between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mi>k</mi></msub><annotation encoding="application/x-tex">W_k</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>H</mi><mi>k</mi></msub><annotation encoding="application/x-tex">H_k</annotation></semantics></math>.</p>
<p>To determine
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mi>k</mi></msub><annotation encoding="application/x-tex">W_k</annotation></semantics></math>,
first it must verify the secant equation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mi>k</mi></msub><msub><mi>y</mi><mi>k</mi></msub><mo>=</mo><msub><mi>s</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">H_k y_k =s_k</annotation></semantics></math>
or
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>k</mi></msub><mo>=</mo><msub><mi>W</mi><mi>k</mi></msub><msub><mi>s</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">y_k=W_k s_k</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>k</mi></msub><mo>=</mo><msub><mi>g</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>−</mo><msub><mi>g</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">y_k = g_{k+1}-g_k</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>k</mi></msub><mo>=</mo><msub><mi>x</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>−</mo><msub><mi>x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">s_k=x_{k+1}-x_k</annotation></semantics></math>.
To define the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mo>−</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">n(n-1)</annotation></semantics></math>
terms, we generally impose a symmetry and a minimum distance conditions.
We say we have a rank 2 update if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mi>k</mi></msub><mo>=</mo><msub><mi>H</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>a</mi><mi>u</mi><msup><mi>u</mi><mi>T</mi></msup><mo>+</mo><mi>b</mi><mi>v</mi><msup><mi>v</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">H_k = H_{k-1} + a u u^T + b v v^T</annotation></semantics></math>
and a rank 1 update if $H_k = H_{k-1} + a u u^T $. Rank
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
update is justified by the spectral decomposition theorem.</p>
<p>There are two rank-2 updates which are symmetric and preserve
positive definiteness</p>
<ul>
<li>DFP minimizes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>min</mo><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mi>H</mi><mo>−</mo><msub><mi>H</mi><mi>k</mi></msub><msub><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mi>F</mi></msub></mrow><annotation encoding="application/x-tex">\min || H - H_k ||_F</annotation></semantics></math>
such that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>=</mo><msup><mi>H</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">H=H^T</annotation></semantics></math>:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>I</mi><mo>−</mo><mfrac><mrow><msub><mi>y</mi><mi>k</mi></msub><msubsup><mi>s</mi><mi>k</mi><mi>T</mi></msubsup></mrow><mrow><msubsup><mi>y</mi><mi>k</mi><mi>T</mi></msubsup><msub><mi>s</mi><mi>k</mi></msub></mrow></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>H</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>I</mi><mo>−</mo><mfrac><mrow><msub><mi>s</mi><mi>k</mi></msub><msubsup><mi>y</mi><mi>k</mi><mi>T</mi></msubsup></mrow><mrow><msubsup><mi>y</mi><mi>k</mi><mi>T</mi></msubsup><msub><mi>s</mi><mi>k</mi></msub></mrow></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mfrac><mrow><msub><mi>y</mi><mi>k</mi></msub><msubsup><mi>y</mi><mi>k</mi><mi>T</mi></msubsup></mrow><mrow><msubsup><mi>y</mi><mi>k</mi><mi>T</mi></msubsup><msub><mi>s</mi><mi>k</mi></msub></mrow></mfrac><mo>⇔</mo><msub><mi>W</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>W</mi><mi>k</mi></msub><mo>+</mo><mfrac><mrow><msub><mi>s</mi><mi>k</mi></msub><msubsup><mi>s</mi><mi>k</mi><mi>T</mi></msubsup></mrow><mrow><msubsup><mi>y</mi><mi>k</mi><mi>T</mi></msubsup><msub><mi>s</mi><mi>k</mi></msub></mrow></mfrac><mo>−</mo><mfrac><mrow><msub><mi>W</mi><mi>k</mi></msub><msub><mi>y</mi><mi>k</mi></msub><msubsup><mi>y</mi><mi>k</mi><mi>T</mi></msubsup><msubsup><mi>W</mi><mi>k</mi><mi>T</mi></msubsup></mrow><mrow><msubsup><mi>y</mi><mi>k</mi><mi>T</mi></msubsup><msub><mi>W</mi><mi>k</mi></msub><msub><mi>y</mi><mi>k</mi></msub></mrow></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex"> 
H_{k+1} = \left (I-\frac {y_k s_k^T} {y_k^T s_k} \right ) H_k \left (I-\frac {s_k y_k^T} {y_k^T s_k} \right )+\frac{y_k y_k^T} {y_k^T s_k}  
\Leftrightarrow
W_{k+1} = W_k +  \frac{s_k s_k^T}{y_k^{T} s_k} - \frac {W_k y_k y_k^T W_k^T} {y_k^T W_k y_k} .
</annotation></semantics></math><br>
</li>
<li>BFGS minimizes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>min</mo><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mi>W</mi><mo>−</mo><msub><mi>W</mi><mi>k</mi></msub><msub><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mi>F</mi></msub></mrow><annotation encoding="application/x-tex">\min || W - W_k ||_F</annotation></semantics></math>
such that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>=</mo><msup><mi>W</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">W=W^T</annotation></semantics></math>:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>H</mi><mi>k</mi></msub><mo>−</mo><mfrac><mrow><msub><mi>H</mi><mi>k</mi></msub><msub><mi>y</mi><mi>k</mi></msub><msubsup><mi>y</mi><mi>k</mi><mi>T</mi></msubsup><msub><mi>H</mi><mi>k</mi></msub></mrow><mrow><msubsup><mi>y</mi><mi>k</mi><mi>T</mi></msubsup><msub><mi>H</mi><mi>k</mi></msub><msub><mi>y</mi><mi>k</mi></msub></mrow></mfrac><mo>+</mo><mfrac><mrow><msub><mi>s</mi><mi>k</mi></msub><msubsup><mi>s</mi><mi>k</mi><mi>T</mi></msubsup></mrow><mrow><msubsup><mi>y</mi><mi>k</mi><mi>T</mi></msubsup><msub><mi>s</mi><mi>k</mi></msub></mrow></mfrac><mo>⇔</mo><msub><mi>W</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>I</mi><mo>−</mo><mfrac><mrow><msub><mi>y</mi><mi>k</mi></msub><msubsup><mi>s</mi><mi>k</mi><mi>T</mi></msubsup></mrow><mrow><msubsup><mi>y</mi><mi>k</mi><mi>T</mi></msubsup><msub><mi>s</mi><mi>k</mi></msub></mrow></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mi>T</mi></msup><msub><mi>W</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>I</mi><mo>−</mo><mfrac><mrow><msub><mi>y</mi><mi>k</mi></msub><msubsup><mi>s</mi><mi>k</mi><mi>T</mi></msubsup></mrow><mrow><msubsup><mi>y</mi><mi>k</mi><mi>T</mi></msubsup><msub><mi>s</mi><mi>k</mi></msub></mrow></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mfrac><mrow><msub><mi>s</mi><mi>k</mi></msub><msubsup><mi>s</mi><mi>k</mi><mi>T</mi></msubsup></mrow><mrow><msubsup><mi>y</mi><mi>k</mi><mi>T</mi></msubsup><msub><mi>s</mi><mi>k</mi></msub></mrow></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex">
H_{k+1} = H_k - \frac{ H_k y_k y_k^T H_k }{ y_k^T H_k y_k }  + \frac{ s_k s_k^T }{ y_k^T s_k }
\Leftrightarrow
W_{k+1} = \left (I-\frac {y_k s_k^T} {y_k^T s_k} \right )^T W_k \left (I-\frac { y_k s_k^T} {y_k^T s_k} \right )+\frac{s_k s_k^T} {y_k^T s_k} .
</annotation></semantics></math>
</li>
</ul>
<p>In <code>R</code>, the so-called BFGS scheme is implemented in
<code>optim</code>.</p>
<p>Another possible method (which is initially arised from quadratic
problems) is the nonlinear conjugate gradients. This consists in
computing directions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>d</mi><mn>0</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(d_0, \dots, d_k)</annotation></semantics></math>
that are conjugate with respect to a matrix close to the true Hessian
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">H(x_k)</annotation></semantics></math>.
Directions are computed iteratively by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><mo>−</mo><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><msub><mi>β</mi><mi>k</mi></msub><msub><mi>d</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">d_k = -g(x_k) + \beta_k d_{k-1}</annotation></semantics></math>
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k&gt;1</annotation></semantics></math>,
once initiated by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>=</mo><mo>−</mo><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">d_1 = -g(x_1)</annotation></semantics></math>.
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>β</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\beta_k</annotation></semantics></math>
are updated according a scheme:</p>
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>k</mi></msub><mo>=</mo><mfrac><mrow><msubsup><mi>g</mi><mi>k</mi><mi>T</mi></msubsup><msub><mi>g</mi><mi>k</mi></msub></mrow><mrow><msubsup><mi>g</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow><mi>T</mi></msubsup><msub><mi>g</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\beta_k = \frac{ g_k^T g_k}{g_{k-1}^T g_{k-1} }</annotation></semantics></math>:
Fletcher-Reeves update,</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>k</mi></msub><mo>=</mo><mfrac><mrow><msubsup><mi>g</mi><mi>k</mi><mi>T</mi></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>g</mi><mi>k</mi></msub><mo>−</mo><msub><mi>g</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><msubsup><mi>g</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow><mi>T</mi></msubsup><msub><mi>g</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\beta_k = \frac{ g_k^T (g_k-g_{k-1} )}{g_{k-1}^T g_{k-1}}</annotation></semantics></math>:
Polak-Ribiere update.</li>
</ul>
<p>There exists also three-term formula for computing direction
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><mo>−</mo><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><msub><mi>β</mi><mi>k</mi></msub><msub><mi>d</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>γ</mi><mi>k</mi></msub><msub><mi>d</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">d_k = -g(x_k) + \beta_k d_{k-1}+\gamma_{k} d_t</annotation></semantics></math>
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>&lt;</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">t&lt;k</annotation></semantics></math>.
A possible scheme is the Beale-Sorenson update defined as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mi>k</mi></msub><mo>=</mo><mfrac><mrow><msubsup><mi>g</mi><mi>k</mi><mi>T</mi></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>g</mi><mi>k</mi></msub><mo>−</mo><msub><mi>g</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><msubsup><mi>d</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow><mi>T</mi></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>g</mi><mi>k</mi></msub><mo>−</mo><msub><mi>g</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">\beta_k = \frac{ g_k^T (g_k-g_{k-1} )}{d^T_{k-1}(g_{k}- g_{k-1})}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>γ</mi><mi>k</mi></msub><mo>=</mo><mfrac><mrow><msubsup><mi>g</mi><mi>k</mi><mi>T</mi></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>g</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>−</mo><msub><mi>g</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><msubsup><mi>d</mi><mi>t</mi><mi>T</mi></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>g</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>−</mo><msub><mi>g</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">\gamma_k = \frac{ g_k^T (g_{t+1}-g_{t} )}{d^T_{t}(g_{t+1}- g_{t})}</annotation></semantics></math>
if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>&gt;</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k&gt;t+1</annotation></semantics></math>
otherwise
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>γ</mi><mi>k</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\gamma_k=0</annotation></semantics></math>
if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mi>t</mi></mrow><annotation encoding="application/x-tex">k=t</annotation></semantics></math>.
See Yuan (2006) for other well-known schemes such as Hestenses-Stiefel,
Dixon or Conjugate-Descent. The three updates (Fletcher-Reeves,
Polak-Ribiere, Beale-Sorenson) of the (non-linear) conjugate gradient
are available in <code>optim</code>.</p>
</div>
<div class="section level4">
<h4 id="computing-the-stepsize-t_k">1.2.2. Computing the stepsize
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>t</mi><mi>k</mi></msub><annotation encoding="application/x-tex">t_k</annotation></semantics></math><a class="anchor" aria-label="anchor" href="#computing-the-stepsize-t_k"></a>
</h4>
<p>Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϕ</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo>+</mo><mi>t</mi><msub><mi>d</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\phi_k(t) = f(x_k + t d_k)</annotation></semantics></math>
for a given direction/iterate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>d</mi><mi>k</mi></msub><mo>,</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(d_k, x_k)</annotation></semantics></math>.
We need to find conditions to find a satisfactory stepsize
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>t</mi><mi>k</mi></msub><annotation encoding="application/x-tex">t_k</annotation></semantics></math>.
In literature, we consider the descent condition:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϕ</mi><mi>k</mi></msub><mi>′</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>&lt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\phi_k'(0) &lt; 0</annotation></semantics></math>
and the Armijo condition:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϕ</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≤</mo><msub><mi>ϕ</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>t</mi><msub><mi>c</mi><mn>1</mn></msub><msub><mi>ϕ</mi><mi>k</mi></msub><mi>′</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\phi_k(t) \leq \phi_k(0) + t c_1 \phi_k'(0)</annotation></semantics></math>
ensures a decrease of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>.
Nocedal &amp; Wright (2006) presents a backtracking (or geometric)
approach satisfying the Armijo condition and minimal condition,
i.e. Goldstein and Price condition.</p>
<ul>
<li>set
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>t</mi><mrow><mi>k</mi><mo>,</mo><mn>0</mn></mrow></msub><annotation encoding="application/x-tex">t_{k,0}</annotation></semantics></math>
e.g. 1,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>&lt;</mo><mi>α</mi><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 &lt; \alpha &lt; 1</annotation></semantics></math>,</li>
<li>
<strong>Repeat</strong> until Armijo satisfied,
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>k</mi><mo>,</mo><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>α</mi><mo>×</mo><msub><mi>t</mi><mrow><mi>k</mi><mo>,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t_{k,i+1} =  \alpha \times t_{k,i}</annotation></semantics></math>.</li>
</ul>
</li>
<li><strong>end Repeat</strong></li>
</ul>
<p>This backtracking linesearch is available in <code>optim</code>.</p>
</div>
</div>
<div class="section level3">
<h3 id="benchmark">1.3. Benchmark<a class="anchor" aria-label="anchor" href="#benchmark"></a>
</h3>
<p>To simplify the benchmark of optimization methods, we create a
<code>fitbench</code> function that computes the desired estimation
method for all optimization methods. This function is currently not
exported in the package.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>fitbench <span class="ot">&lt;-</span> <span class="cf">function</span>(data, distr, method, <span class="at">grad =</span> <span class="cn">NULL</span>, </span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>                     <span class="at">control =</span> <span class="fu">list</span>(<span class="at">trace =</span> <span class="dv">0</span>, <span class="at">REPORT =</span> <span class="dv">1</span>, <span class="at">maxit =</span> <span class="dv">1000</span>), </span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>                     <span class="at">lower =</span> <span class="sc">-</span><span class="cn">Inf</span>, <span class="at">upper =</span> <span class="sc">+</span><span class="cn">Inf</span>, ...) </span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="numerical-illustration-with-the-beta-distribution">2. Numerical illustration with the beta distribution<a class="anchor" aria-label="anchor" href="#numerical-illustration-with-the-beta-distribution"></a>
</h2>
<div class="section level3">
<h3 id="log-likelihood-function-and-its-gradient-for-beta-distribution">2.1. Log-likelihood function and its gradient for beta
distribution<a class="anchor" aria-label="anchor" href="#log-likelihood-function-and-its-gradient-for-beta-distribution"></a>
</h3>
<div class="section level4">
<h4 id="theoretical-value">2.1.1. Theoretical value<a class="anchor" aria-label="anchor" href="#theoretical-value"></a>
</h4>
<p>The density of the beta distribution is given by
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>;</mo><msub><mi>δ</mi><mn>1</mn></msub><mo>,</mo><msub><mi>δ</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><msup><mi>x</mi><mrow><msub><mi>δ</mi><mn>1</mn></msub><mo>−</mo><mn>1</mn></mrow></msup><msup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><msub><mi>δ</mi><mn>2</mn></msub><mo>−</mo><mn>1</mn></mrow></msup></mrow><mrow><mi>β</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>δ</mi><mn>1</mn></msub><mo>,</mo><msub><mi>δ</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mo>,</mo></mrow><annotation encoding="application/x-tex">
f(x; \delta_1,\delta_2) = \frac{x^{\delta_1-1}(1-x)^{\delta_2-1}}{\beta(\delta_1,\delta_2)},
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation></semantics></math>
denotes the beta function, see the NIST Handbook of mathematical
functions <a href="https://dlmf.nist.gov/" class="external-link uri">https://dlmf.nist.gov/</a>. We recall that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>Γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>Γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>b</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>/</mi><mi>Γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo>+</mo><mi>b</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\beta(a,b)=\Gamma(a)\Gamma(b)/\Gamma(a+b)</annotation></semantics></math>.
There the log-likelihood for a set of observations
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(x_1,\dots,x_n)</annotation></semantics></math>
is
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>log</mo><mi>L</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>δ</mi><mn>1</mn></msub><mo>,</mo><msub><mi>δ</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>δ</mi><mn>1</mn></msub><mo>−</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>δ</mi><mn>2</mn></msub><mo>−</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>n</mi><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>β</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>δ</mi><mn>1</mn></msub><mo>,</mo><msub><mi>δ</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\log L(\delta_1,\delta_2) = (\delta_1-1)\sum_{i=1}^n\log(x_i)+ (\delta_2-1)\sum_{i=1}^n\log(1-x_i)+ n \log(\beta(\delta_1,\delta_2))
</annotation></semantics></math> The gradient with respect to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>b</mi><annotation encoding="application/x-tex">b</annotation></semantics></math>
is
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>∇</mi><mo>log</mo><mi>L</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>δ</mi><mn>1</mn></msub><mo>,</mo><msub><mi>δ</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo>ln</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>n</mi><mi>ψ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>δ</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>n</mi><mi>ψ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>δ</mi><mn>1</mn></msub><mo>+</mo><msub><mi>δ</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo>ln</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>n</mi><mi>ψ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>δ</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>n</mi><mi>ψ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>δ</mi><mn>1</mn></msub><mo>+</mo><msub><mi>δ</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr></mtable><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">
\nabla \log L(\delta_1,\delta_2) = 
\left(\begin{matrix}
\sum\limits_{i=1}^n\ln(x_i) - n\psi(\delta_1)+n\psi( \delta_1+\delta_2)  \\
\sum\limits_{i=1}^n\ln(1-x_i)- n\psi(\delta_2)+n\psi( \delta_1+\delta_2)
\end{matrix}\right),
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ψ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>Γ</mi><mi>′</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>/</mi><mi>Γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\psi(x)=\Gamma'(x)/\Gamma(x)</annotation></semantics></math>
is the digamma function, see the NIST Handbook of mathematical functions
<a href="https://dlmf.nist.gov/" class="external-link uri">https://dlmf.nist.gov/</a>.</p>
</div>
<div class="section level4">
<h4 id="r-implementation">2.1.2. <code>R</code> implementation<a class="anchor" aria-label="anchor" href="#r-implementation"></a>
</h4>
<p>As in the <code>fitdistrplus</code> package, we minimize the opposite
of the log-likelihood: we implement the opposite of the gradient in
<code>grlnL</code>. Both the log-likelihood and its gradient are not
exported.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lnL</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">par</span>, <span class="va">fix.arg</span>, <span class="va">obs</span>, <span class="va">ddistnam</span><span class="op">)</span> </span>
<span>  <span class="fu">fitdistrplus</span><span class="fu">:::</span><span class="fu">loglikelihood</span><span class="op">(</span><span class="va">par</span>, <span class="va">fix.arg</span>, <span class="va">obs</span>, <span class="va">ddistnam</span><span class="op">)</span> </span>
<span><span class="va">grlnlbeta</span> <span class="op">&lt;-</span> <span class="fu">fitdistrplus</span><span class="fu">:::</span><span class="va">grlnlbeta</span></span></code></pre></div>
</div>
</div>
<div class="section level3">
<h3 id="random-generation-of-a-sample">2.2. Random generation of a sample<a class="anchor" aria-label="anchor" href="#random-generation-of-a-sample"></a>
</h3>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#(1) beta distribution</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">200</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html" class="external-link">rbeta</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">3</span>, <span class="fl">3</span><span class="op">/</span><span class="fl">4</span><span class="op">)</span></span>
<span><span class="fu">grlnlbeta</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">4</span><span class="op">)</span>, <span class="va">x</span><span class="op">)</span> <span class="co">#test</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] -133  317</span></span></code></pre>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html" class="external-link">hist</a></span><span class="op">(</span><span class="va">x</span>, prob<span class="op">=</span><span class="cn">TRUE</span>, xlim<span class="op">=</span><span class="fl">0</span><span class="op">:</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/density.html" class="external-link">density</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, col<span class="op">=</span><span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html" class="external-link">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Beta.html" class="external-link">dbeta</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">3</span>, <span class="fl">3</span><span class="op">/</span><span class="fl">4</span><span class="op">)</span>, col<span class="op">=</span><span class="st">"green"</span>, add<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/legend.html" class="external-link">legend</a></span><span class="op">(</span><span class="st">"topleft"</span>, lty<span class="op">=</span><span class="fl">1</span>, col<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"red"</span>,<span class="st">"green"</span><span class="op">)</span>, legend<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"empirical"</span>, <span class="st">"theoretical"</span><span class="op">)</span>, bty<span class="op">=</span><span class="st">"n"</span><span class="op">)</span></span></code></pre></div>
<p><img src="Optimalgo_files/figure-html/unnamed-chunk-4-1.png" class="r-plt" width="384"></p>
</div>
<div class="section level3">
<h3 id="fit-beta-distribution">2.3 Fit Beta distribution<a class="anchor" aria-label="anchor" href="#fit-beta-distribution"></a>
</h3>
<p>Define control parameters.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ctr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>trace<span class="op">=</span><span class="fl">0</span>, REPORT<span class="op">=</span><span class="fl">1</span>, maxit<span class="op">=</span><span class="fl">1000</span><span class="op">)</span></span></code></pre></div>
<p>Call <code>mledist</code> with the default optimization function
(<code>optim</code> implemented in <code>stats</code> package) with and
without the gradient for the different optimization methods.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">unconstropt</span> <span class="op">&lt;-</span> <span class="fu">fitbench</span><span class="op">(</span><span class="va">x</span>, <span class="st">"beta"</span>, <span class="st">"mle"</span>, grad<span class="op">=</span><span class="va">grlnlbeta</span>, lower<span class="op">=</span><span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##     BFGS       NM     CGFR     CGPR     CGBS L-BFGS-B     NM-B   G-BFGS </span></span>
<span><span class="co">##       14       14       14       14       14       14       14       14 </span></span>
<span><span class="co">##   G-CGFR   G-CGPR   G-CGBS G-BFGS-B   G-NM-B G-CGFR-B G-CGPR-B G-CGBS-B </span></span>
<span><span class="co">##       14       14       14       14       14       14       14       14</span></span></code></pre>
<p>In the case of constrained optimization, <code>mledist</code> permits
the direct use of <code>constrOptim</code> function (still implemented
in <code>stats</code> package) that allow linear inequality constraints
by using a logarithmic barrier.</p>
<p>Use a exp/log transformation of the shape parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>δ</mi><mn>1</mn></msub><annotation encoding="application/x-tex">\delta_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>δ</mi><mn>2</mn></msub><annotation encoding="application/x-tex">\delta_2</annotation></semantics></math>
to ensure that the shape parameters are strictly positive.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dbeta2</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">shape1</span>, <span class="va">shape2</span>, <span class="va">log</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html" class="external-link">dbeta</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">shape1</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">shape2</span><span class="op">)</span>, log<span class="op">=</span><span class="va">log</span><span class="op">)</span></span>
<span><span class="co">#take the log of the starting values</span></span>
<span><span class="va">startarg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="fu">fitdistrplus</span><span class="fu">:::</span><span class="fu">startargdefault</span><span class="op">(</span><span class="va">x</span>, <span class="st">"beta"</span><span class="op">)</span>, <span class="va">log</span><span class="op">)</span></span>
<span><span class="co">#redefine the gradient for the new parametrization</span></span>
<span><span class="va">grbetaexp</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">par</span>, <span class="va">obs</span>, <span class="va">...</span><span class="op">)</span> </span>
<span>    <span class="fu">grlnlbeta</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">par</span><span class="op">)</span>, <span class="va">obs</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">par</span><span class="op">)</span></span>
<span>    </span>
<span></span>
<span><span class="va">expopt</span> <span class="op">&lt;-</span> <span class="fu">fitbench</span><span class="op">(</span><span class="va">x</span>, distr<span class="op">=</span><span class="st">"beta2"</span>, method<span class="op">=</span><span class="st">"mle"</span>, grad<span class="op">=</span><span class="va">grbetaexp</span>, start<span class="op">=</span><span class="va">startarg</span><span class="op">)</span> </span></code></pre></div>
<pre><code><span><span class="co">##   BFGS     NM   CGFR   CGPR   CGBS G-BFGS G-CGFR G-CGPR G-CGBS </span></span>
<span><span class="co">##     14     14     14     14     14     14     14     14     14</span></span></code></pre>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#get back to original parametrization</span></span>
<span><span class="va">expopt</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"fitted shape1"</span>, <span class="st">"fitted shape2"</span><span class="op">)</span>, <span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">expopt</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"fitted shape1"</span>, <span class="st">"fitted shape2"</span><span class="op">)</span>, <span class="op">]</span><span class="op">)</span></span></code></pre></div>
<p>Then we extract the values of the fitted parameters, the value of the
corresponding log-likelihood and the number of counts to the function to
minimize and its gradient (whether it is the theoretical gradient or the
numerically approximated one).</p>
</div>
<div class="section level3">
<h3 id="results-of-the-numerical-investigation">2.4. Results of the numerical investigation<a class="anchor" aria-label="anchor" href="#results-of-the-numerical-investigation"></a>
</h3>
<p>Results are displayed in the following tables: (1) the original
parametrization without specifying the gradient (<code>-B</code> stands
for bounded version), (2) the original parametrization with the (true)
gradient (<code>-B</code> stands for bounded version and <code>-G</code>
for gradient), (3) the log-transformed parametrization without
specifying the gradient, (4) the log-transformed parametrization with
the (true) gradient (<code>-G</code> stands for gradient).</p>
<table class="table">
<caption>Unconstrained optimization with approximated gradient</caption>
<colgroup>
<col width="21%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="12%">
<col width="10%">
</colgroup>
<thead><tr class="header">
<th align="left"></th>
<th align="right">BFGS</th>
<th align="right">NM</th>
<th align="right">CGFR</th>
<th align="right">CGPR</th>
<th align="right">CGBS</th>
<th align="right">L-BFGS-B</th>
<th align="right">NM-B</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">fitted shape1</td>
<td align="right">2.665</td>
<td align="right">2.664</td>
<td align="right">2.665</td>
<td align="right">2.665</td>
<td align="right">2.665</td>
<td align="right">2.665</td>
<td align="right">2.665</td>
</tr>
<tr class="even">
<td align="left">fitted shape2</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
</tr>
<tr class="odd">
<td align="left">fitted loglik</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
</tr>
<tr class="even">
<td align="left">func. eval. nb.</td>
<td align="right">15.000</td>
<td align="right">47.000</td>
<td align="right">191.000</td>
<td align="right">221.000</td>
<td align="right">242.000</td>
<td align="right">8.000</td>
<td align="right">92.000</td>
</tr>
<tr class="odd">
<td align="left">grad. eval. nb.</td>
<td align="right">11.000</td>
<td align="right">NA</td>
<td align="right">95.000</td>
<td align="right">115.000</td>
<td align="right">175.000</td>
<td align="right">8.000</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">time (sec)</td>
<td align="right">0.007</td>
<td align="right">0.004</td>
<td align="right">0.034</td>
<td align="right">0.041</td>
<td align="right">0.056</td>
<td align="right">0.003</td>
<td align="right">0.011</td>
</tr>
</tbody>
</table>
<table class="table">
<caption>Unconstrained optimization with true gradient</caption>
<colgroup>
<col width="17%">
<col width="8%">
<col width="8%">
<col width="8%">
<col width="8%">
<col width="9%">
<col width="8%">
<col width="9%">
<col width="9%">
<col width="9%">
</colgroup>
<thead><tr class="header">
<th align="left"></th>
<th align="right">G-BFGS</th>
<th align="right">G-CGFR</th>
<th align="right">G-CGPR</th>
<th align="right">G-CGBS</th>
<th align="right">G-BFGS-B</th>
<th align="right">G-NM-B</th>
<th align="right">G-CGFR-B</th>
<th align="right">G-CGPR-B</th>
<th align="right">G-CGBS-B</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">fitted shape1</td>
<td align="right">2.665</td>
<td align="right">2.665</td>
<td align="right">2.665</td>
<td align="right">2.665</td>
<td align="right">2.665</td>
<td align="right">2.665</td>
<td align="right">2.665</td>
<td align="right">2.665</td>
<td align="right">2.665</td>
</tr>
<tr class="even">
<td align="left">fitted shape2</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
</tr>
<tr class="odd">
<td align="left">fitted loglik</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
</tr>
<tr class="even">
<td align="left">func. eval. nb.</td>
<td align="right">22.000</td>
<td align="right">249.000</td>
<td align="right">239.000</td>
<td align="right">138.000</td>
<td align="right">40.000</td>
<td align="right">92.000</td>
<td align="right">433.000</td>
<td align="right">345.000</td>
<td align="right">255.000</td>
</tr>
<tr class="odd">
<td align="left">grad. eval. nb.</td>
<td align="right">5.000</td>
<td align="right">71.000</td>
<td align="right">67.000</td>
<td align="right">43.000</td>
<td align="right">6.000</td>
<td align="right">NA</td>
<td align="right">92.000</td>
<td align="right">82.000</td>
<td align="right">58.000</td>
</tr>
<tr class="even">
<td align="left">time (sec)</td>
<td align="right">0.010</td>
<td align="right">0.080</td>
<td align="right">0.076</td>
<td align="right">0.049</td>
<td align="right">0.021</td>
<td align="right">0.020</td>
<td align="right">0.129</td>
<td align="right">0.108</td>
<td align="right">0.082</td>
</tr>
</tbody>
</table>
<table class="table">
<caption>Exponential trick optimization with approximated
gradient</caption>
<thead><tr class="header">
<th align="left"></th>
<th align="right">BFGS</th>
<th align="right">NM</th>
<th align="right">CGFR</th>
<th align="right">CGPR</th>
<th align="right">CGBS</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">fitted shape1</td>
<td align="right">2.665</td>
<td align="right">2.664</td>
<td align="right">2.665</td>
<td align="right">2.665</td>
<td align="right">2.665</td>
</tr>
<tr class="even">
<td align="left">fitted shape2</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
</tr>
<tr class="odd">
<td align="left">fitted loglik</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
</tr>
<tr class="even">
<td align="left">func. eval. nb.</td>
<td align="right">8.000</td>
<td align="right">41.000</td>
<td align="right">37.000</td>
<td align="right">49.000</td>
<td align="right">47.000</td>
</tr>
<tr class="odd">
<td align="left">grad. eval. nb.</td>
<td align="right">5.000</td>
<td align="right">NA</td>
<td align="right">19.000</td>
<td align="right">39.000</td>
<td align="right">33.000</td>
</tr>
<tr class="even">
<td align="left">time (sec)</td>
<td align="right">0.014</td>
<td align="right">0.004</td>
<td align="right">0.008</td>
<td align="right">0.013</td>
<td align="right">0.011</td>
</tr>
</tbody>
</table>
<table class="table">
<caption>Exponential trick optimization with true gradient</caption>
<thead><tr class="header">
<th align="left"></th>
<th align="right">G-BFGS</th>
<th align="right">G-CGFR</th>
<th align="right">G-CGPR</th>
<th align="right">G-CGBS</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">fitted shape1</td>
<td align="right">2.665</td>
<td align="right">2.665</td>
<td align="right">2.665</td>
<td align="right">2.665</td>
</tr>
<tr class="even">
<td align="left">fitted shape2</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
<td align="right">0.731</td>
</tr>
<tr class="odd">
<td align="left">fitted loglik</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
<td align="right">114.165</td>
</tr>
<tr class="even">
<td align="left">func. eval. nb.</td>
<td align="right">21.000</td>
<td align="right">109.000</td>
<td align="right">146.000</td>
<td align="right">112.000</td>
</tr>
<tr class="odd">
<td align="left">grad. eval. nb.</td>
<td align="right">5.000</td>
<td align="right">29.000</td>
<td align="right">47.000</td>
<td align="right">35.000</td>
</tr>
<tr class="even">
<td align="left">time (sec)</td>
<td align="right">0.011</td>
<td align="right">0.036</td>
<td align="right">0.055</td>
<td align="right">0.041</td>
</tr>
</tbody>
</table>
<p>Using <code>llsurface</code>, we plot the log-likehood surface around
the true value (green) and the fitted parameters (red).</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/logLik-surface.html">llsurface</a></span><span class="op">(</span>min.arg<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.1</span><span class="op">)</span>, max.arg<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">7</span>, <span class="fl">3</span><span class="op">)</span>, xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">.1</span>,<span class="fl">7</span><span class="op">)</span>, </span>
<span>          plot.arg<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"shape1"</span>, <span class="st">"shape2"</span><span class="op">)</span>, nlev<span class="op">=</span><span class="fl">25</span>,</span>
<span>          lseq<span class="op">=</span><span class="fl">50</span>, data<span class="op">=</span><span class="va">x</span>, distr<span class="op">=</span><span class="st">"beta"</span>, back.col <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html" class="external-link">points</a></span><span class="op">(</span><span class="va">unconstropt</span><span class="op">[</span><span class="fl">1</span>,<span class="st">"BFGS"</span><span class="op">]</span>, <span class="va">unconstropt</span><span class="op">[</span><span class="fl">2</span>,<span class="st">"BFGS"</span><span class="op">]</span>, pch<span class="op">=</span><span class="st">"+"</span>, col<span class="op">=</span><span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html" class="external-link">points</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">3</span><span class="op">/</span><span class="fl">4</span>, pch<span class="op">=</span><span class="st">"x"</span>, col<span class="op">=</span><span class="st">"green"</span><span class="op">)</span></span></code></pre></div>
<p><img src="Optimalgo_files/figure-html/unnamed-chunk-12-1.png" class="r-plt" width="384"></p>
<p>We can simulate bootstrap replicates using the <code>bootdist</code>
function.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">b1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bootdist.html">bootdist</a></span><span class="op">(</span><span class="fu"><a href="../reference/fitdist.html">fitdist</a></span><span class="op">(</span><span class="va">x</span>, <span class="st">"beta"</span>, method <span class="op">=</span> <span class="st">"mle"</span>, optim.method <span class="op">=</span> <span class="st">"BFGS"</span><span class="op">)</span>, </span>
<span>               niter <span class="op">=</span> <span class="fl">100</span>, parallel <span class="op">=</span> <span class="st">"snow"</span>, ncpus <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">b1</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Parametric bootstrap medians and 95% percentile CI </span></span>
<span><span class="co">##        Median  2.5% 97.5%</span></span>
<span><span class="co">## shape1   2.73 2.272 3.283</span></span>
<span><span class="co">## shape2   0.75 0.652 0.888</span></span></code></pre>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">b1</span>, trueval <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">3</span><span class="op">/</span><span class="fl">4</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="Optimalgo_files/figure-html/unnamed-chunk-13-1.png" class="r-plt" width="384"></p>
</div>
</div>
<div class="section level2">
<h2 id="numerical-illustration-with-the-negative-binomial-distribution">3. Numerical illustration with the negative binomial
distribution<a class="anchor" aria-label="anchor" href="#numerical-illustration-with-the-negative-binomial-distribution"></a>
</h2>
<div class="section level3">
<h3 id="log-likelihood-function-and-its-gradient-for-negative-binomial-distribution">3.1. Log-likelihood function and its gradient for negative binomial
distribution<a class="anchor" aria-label="anchor" href="#log-likelihood-function-and-its-gradient-for-negative-binomial-distribution"></a>
</h3>
<div class="section level4">
<h4 id="theoretical-value-1">3.1.1. Theoretical value<a class="anchor" aria-label="anchor" href="#theoretical-value-1"></a>
</h4>
<p>The p.m.f. of the Negative binomial distribution is given by
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>;</mo><mi>m</mi><mo>,</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><mi>Γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>+</mo><mi>m</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>Γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>m</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>x</mi><mi>!</mi></mrow></mfrac><msup><mi>p</mi><mi>m</mi></msup><msup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>x</mi></msup><mo>,</mo></mrow><annotation encoding="application/x-tex">
f(x; m,p) = \frac{\Gamma(x+m)}{\Gamma(m)x!} p^m (1-p)^x,
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Γ</mi><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math>
denotes the beta function, see the NIST Handbook of mathematical
functions <a href="https://dlmf.nist.gov/" class="external-link uri">https://dlmf.nist.gov/</a>. There exists an alternative
representation where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo>=</mo><mi>m</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>/</mi><mi>p</mi></mrow><annotation encoding="application/x-tex">\mu=m (1-p)/p</annotation></semantics></math>
or equivalently
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mi>m</mi><mi>/</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>m</mi><mo>+</mo><mi>μ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p=m/(m+\mu)</annotation></semantics></math>.
Thus, the log-likelihood for a set of observations
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(x_1,\dots,x_n)</annotation></semantics></math>
is
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>log</mo><mi>L</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>m</mi><mo>,</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo>log</mo><mi>Γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mi>m</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>n</mi><mo>log</mo><mi>Γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>m</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi>!</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>m</mi><mi>n</mi><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>x</mi><mi>i</mi></msub><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\log L(m,p) = 
\sum_{i=1}^{n} \log\Gamma(x_i+m)
-n\log\Gamma(m)
-\sum_{i=1}^{n} \log(x_i!)
+ mn\log(p)
+\sum_{i=1}^{n} {x_i}\log(1-p)
</annotation></semantics></math> The gradient with respect to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>
is
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>∇</mi><mo>log</mo><mi>L</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>m</mi><mo>,</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>ψ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mi>m</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mi>n</mi><mi>ψ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>m</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>n</mi><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mi>m</mi><mi>n</mi><mi>/</mi><mi>p</mi><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>x</mi><mi>i</mi></msub><mi>/</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr></mtable><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">
\nabla \log L(m,p) = 
\left(\begin{matrix}
\sum_{i=1}^{n} \psi(x_i+m)
-n \psi(m)
+ n\log(p)
\\
 mn/p
-\sum_{i=1}^{n} {x_i}/(1-p)
\end{matrix}\right),
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ψ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>Γ</mi><mi>′</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>/</mi><mi>Γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\psi(x)=\Gamma'(x)/\Gamma(x)</annotation></semantics></math>
is the digamma function, see the NIST Handbook of mathematical functions
<a href="https://dlmf.nist.gov/" class="external-link uri">https://dlmf.nist.gov/</a>.</p>
</div>
<div class="section level4">
<h4 id="r-implementation-1">3.1.2. <code>R</code> implementation<a class="anchor" aria-label="anchor" href="#r-implementation-1"></a>
</h4>
<p>As in the <code>fitdistrplus</code> package, we minimize the opposite
of the log-likelihood: we implement the opposite of the gradient in
<code>grlnL</code>.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">grlnlNB</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">obs</span>, <span class="va">...</span><span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>  <span class="va">m</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span>  <span class="va">p</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span></span>
<span>  <span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">obs</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Special.html" class="external-link">psigamma</a></span><span class="op">(</span><span class="va">obs</span><span class="op">+</span><span class="va">m</span><span class="op">)</span><span class="op">)</span> <span class="op">-</span> <span class="va">n</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Special.html" class="external-link">psigamma</a></span><span class="op">(</span><span class="va">m</span><span class="op">)</span> <span class="op">+</span> <span class="va">n</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span>,</span>
<span>    <span class="va">m</span><span class="op">*</span><span class="va">n</span><span class="op">/</span><span class="va">p</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">obs</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">p</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
</div>
</div>
<div class="section level3">
<h3 id="random-generation-of-a-sample-1">3.2. Random generation of a sample<a class="anchor" aria-label="anchor" href="#random-generation-of-a-sample-1"></a>
</h3>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#(2) negative binomial distribution</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">200</span></span>
<span><span class="va">trueval</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"size"</span><span class="op">=</span><span class="fl">10</span>, <span class="st">"prob"</span><span class="op">=</span><span class="fl">3</span><span class="op">/</span><span class="fl">4</span>, <span class="st">"mu"</span><span class="op">=</span><span class="fl">10</span><span class="op">/</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/NegBinomial.html" class="external-link">rnbinom</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">trueval</span><span class="op">[</span><span class="st">"size"</span><span class="op">]</span>, <span class="va">trueval</span><span class="op">[</span><span class="st">"prob"</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html" class="external-link">hist</a></span><span class="op">(</span><span class="va">x</span>, prob<span class="op">=</span><span class="cn">TRUE</span>, ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">.3</span><span class="op">)</span>, xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/density.html" class="external-link">density</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, col<span class="op">=</span><span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html" class="external-link">points</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/NegBinomial.html" class="external-link">dnbinom</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="va">trueval</span><span class="op">[</span><span class="st">"size"</span><span class="op">]</span>, <span class="va">trueval</span><span class="op">[</span><span class="st">"prob"</span><span class="op">]</span><span class="op">)</span>, </span>
<span>       col <span class="op">=</span> <span class="st">"green"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/legend.html" class="external-link">legend</a></span><span class="op">(</span><span class="st">"topright"</span>, lty <span class="op">=</span> <span class="fl">1</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"red"</span>, <span class="st">"green"</span><span class="op">)</span>, </span>
<span>       legend <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"empirical"</span>, <span class="st">"theoretical"</span><span class="op">)</span>, bty<span class="op">=</span><span class="st">"n"</span><span class="op">)</span></span></code></pre></div>
<p><img src="Optimalgo_files/figure-html/unnamed-chunk-15-1.png" class="r-plt" width="384"></p>
</div>
<div class="section level3">
<h3 id="fit-a-negative-binomial-distribution">3.3. Fit a negative binomial distribution<a class="anchor" aria-label="anchor" href="#fit-a-negative-binomial-distribution"></a>
</h3>
<p>Define control parameters and make the benchmark.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ctr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>trace <span class="op">=</span> <span class="fl">0</span>, REPORT <span class="op">=</span> <span class="fl">1</span>, maxit <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">unconstropt</span> <span class="op">&lt;-</span> <span class="fu">fitbench</span><span class="op">(</span><span class="va">x</span>, <span class="st">"nbinom"</span>, <span class="st">"mle"</span>, grad <span class="op">=</span> <span class="va">grlnlNB</span>, lower <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##     BFGS       NM     CGFR     CGPR     CGBS L-BFGS-B     NM-B   G-BFGS </span></span>
<span><span class="co">##       14       14       14       14       14       14       14       14 </span></span>
<span><span class="co">##   G-CGFR   G-CGPR   G-CGBS G-BFGS-B   G-NM-B G-CGFR-B G-CGPR-B G-CGBS-B </span></span>
<span><span class="co">##       14       14       14       14       14       14       14       14</span></span></code></pre>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">unconstropt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="va">unconstropt</span>, </span>
<span>                     <span class="st">"fitted prob"</span> <span class="op">=</span> <span class="va">unconstropt</span><span class="op">[</span><span class="st">"fitted mu"</span>, <span class="op">]</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="va">unconstropt</span><span class="op">[</span><span class="st">"fitted mu"</span>, <span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>In the case of constrained optimization, <code>mledist</code> permits
the direct use of <code>constrOptim</code> function (still implemented
in <code>stats</code> package) that allow linear inequality constraints
by using a logarithmic barrier.</p>
<p>Use a exp/log transformation of the shape parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>δ</mi><mn>1</mn></msub><annotation encoding="application/x-tex">\delta_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>δ</mi><mn>2</mn></msub><annotation encoding="application/x-tex">\delta_2</annotation></semantics></math>
to ensure that the shape parameters are strictly positive.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dnbinom2</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">size</span>, <span class="va">prob</span>, <span class="va">log</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/NegBinomial.html" class="external-link">dnbinom</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">size</span><span class="op">)</span>, <span class="fl">1</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">prob</span><span class="op">)</span><span class="op">)</span>, log <span class="op">=</span> <span class="va">log</span><span class="op">)</span></span>
<span><span class="co"># transform starting values</span></span>
<span><span class="va">startarg</span> <span class="op">&lt;-</span> <span class="fu">fitdistrplus</span><span class="fu">:::</span><span class="fu">startargdefault</span><span class="op">(</span><span class="va">x</span>, <span class="st">"nbinom"</span><span class="op">)</span></span>
<span><span class="va">startarg</span><span class="op">$</span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">startarg</span><span class="op">$</span><span class="va">size</span> <span class="op">/</span> <span class="op">(</span><span class="va">startarg</span><span class="op">$</span><span class="va">size</span> <span class="op">+</span> <span class="va">startarg</span><span class="op">$</span><span class="va">mu</span><span class="op">)</span></span>
<span><span class="va">startarg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">startarg</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>, </span>
<span>                 prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">startarg</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">startarg</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># redefine the gradient for the new parametrization</span></span>
<span><span class="va">Trans</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html" class="external-link">plogis</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">grNBexp</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">par</span>, <span class="va">obs</span>, <span class="va">...</span><span class="op">)</span> </span>
<span>    <span class="fu">grlnlNB</span><span class="op">(</span><span class="fu">Trans</span><span class="op">(</span><span class="va">par</span><span class="op">)</span>, <span class="va">obs</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">par</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html" class="external-link">plogis</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">*</span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html" class="external-link">plogis</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">expopt</span> <span class="op">&lt;-</span> <span class="fu">fitbench</span><span class="op">(</span><span class="va">x</span>, distr<span class="op">=</span><span class="st">"nbinom2"</span>, method<span class="op">=</span><span class="st">"mle"</span>, grad<span class="op">=</span><span class="va">grNBexp</span>, start<span class="op">=</span><span class="va">startarg</span><span class="op">)</span> </span></code></pre></div>
<pre><code><span><span class="co">##   BFGS     NM   CGFR   CGPR   CGBS G-BFGS G-CGFR G-CGPR G-CGBS </span></span>
<span><span class="co">##     14     14     14     14     14     14     14     14     14</span></span></code></pre>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># get back to original parametrization</span></span>
<span><span class="va">expopt</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"fitted size"</span>, <span class="st">"fitted prob"</span><span class="op">)</span>, <span class="op">]</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">expopt</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"fitted size"</span>, <span class="st">"fitted prob"</span><span class="op">)</span>, <span class="op">]</span>, <span class="fl">2</span>, <span class="va">Trans</span><span class="op">)</span></span></code></pre></div>
<p>Then we extract the values of the fitted parameters, the value of the
corresponding log-likelihood and the number of counts to the function to
minimize and its gradient (whether it is the theoretical gradient or the
numerically approximated one).</p>
</div>
<div class="section level3">
<h3 id="results-of-the-numerical-investigation-1">3.4. Results of the numerical investigation<a class="anchor" aria-label="anchor" href="#results-of-the-numerical-investigation-1"></a>
</h3>
<p>Results are displayed in the following tables: (1) the original
parametrization without specifying the gradient (<code>-B</code> stands
for bounded version), (2) the original parametrization with the (true)
gradient (<code>-B</code> stands for bounded version and <code>-G</code>
for gradient), (3) the log-transformed parametrization without
specifying the gradient, (4) the log-transformed parametrization with
the (true) gradient (<code>-G</code> stands for gradient).</p>
<table style="width:100%;" class="table">
<caption>Unconstrained optimization with approximated gradient</caption>
<colgroup>
<col width="20%">
<col width="11%">
<col width="11%">
<col width="11%">
<col width="11%">
<col width="11%">
<col width="11%">
<col width="11%">
</colgroup>
<thead><tr class="header">
<th align="left"></th>
<th align="right">BFGS</th>
<th align="right">NM</th>
<th align="right">CGFR</th>
<th align="right">CGPR</th>
<th align="right">CGBS</th>
<th align="right">L-BFGS-B</th>
<th align="right">NM-B</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">fitted size</td>
<td align="right">57.333</td>
<td align="right">62.504</td>
<td align="right">57.337</td>
<td align="right">57.335</td>
<td align="right">57.335</td>
<td align="right">57.333</td>
<td align="right">58.446</td>
</tr>
<tr class="even">
<td align="left">fitted mu</td>
<td align="right">3.440</td>
<td align="right">3.440</td>
<td align="right">3.440</td>
<td align="right">3.440</td>
<td align="right">3.440</td>
<td align="right">3.440</td>
<td align="right">3.440</td>
</tr>
<tr class="odd">
<td align="left">fitted loglik</td>
<td align="right">-402.675</td>
<td align="right">-402.674</td>
<td align="right">-402.675</td>
<td align="right">-402.675</td>
<td align="right">-402.675</td>
<td align="right">-402.675</td>
<td align="right">-402.675</td>
</tr>
<tr class="even">
<td align="left">func. eval. nb.</td>
<td align="right">2.000</td>
<td align="right">39.000</td>
<td align="right">2001.000</td>
<td align="right">1001.000</td>
<td align="right">1001.000</td>
<td align="right">2.000</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="left">grad. eval. nb.</td>
<td align="right">1.000</td>
<td align="right">NA</td>
<td align="right">1001.000</td>
<td align="right">1001.000</td>
<td align="right">1001.000</td>
<td align="right">2.000</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">time (sec)</td>
<td align="right">0.001</td>
<td align="right">0.003</td>
<td align="right">0.253</td>
<td align="right">0.203</td>
<td align="right">0.204</td>
<td align="right">0.002</td>
<td align="right">0.004</td>
</tr>
<tr class="odd">
<td align="left">fitted prob</td>
<td align="right">0.775</td>
<td align="right">0.775</td>
<td align="right">0.775</td>
<td align="right">0.775</td>
<td align="right">0.775</td>
<td align="right">0.775</td>
<td align="right">0.775</td>
</tr>
</tbody>
</table>
<table class="table">
<caption>Unconstrained optimization with true gradient</caption>
<colgroup>
<col width="16%">
<col width="9%">
<col width="9%">
<col width="9%">
<col width="9%">
<col width="9%">
<col width="9%">
<col width="9%">
<col width="9%">
<col width="9%">
</colgroup>
<thead><tr class="header">
<th align="left"></th>
<th align="right">G-BFGS</th>
<th align="right">G-CGFR</th>
<th align="right">G-CGPR</th>
<th align="right">G-CGBS</th>
<th align="right">G-BFGS-B</th>
<th align="right">G-NM-B</th>
<th align="right">G-CGFR-B</th>
<th align="right">G-CGPR-B</th>
<th align="right">G-CGBS-B</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">fitted size</td>
<td align="right">57.333</td>
<td align="right">57.333</td>
<td align="right">57.333</td>
<td align="right">57.333</td>
<td align="right">57.333</td>
<td align="right">58.446</td>
<td align="right">57.333</td>
<td align="right">57.333</td>
<td align="right">57.333</td>
</tr>
<tr class="even">
<td align="left">fitted mu</td>
<td align="right">3.440</td>
<td align="right">3.440</td>
<td align="right">3.440</td>
<td align="right">3.440</td>
<td align="right">3.440</td>
<td align="right">3.440</td>
<td align="right">3.440</td>
<td align="right">3.440</td>
<td align="right">3.440</td>
</tr>
<tr class="odd">
<td align="left">fitted loglik</td>
<td align="right">-402.675</td>
<td align="right">-402.675</td>
<td align="right">-402.675</td>
<td align="right">-402.675</td>
<td align="right">-402.675</td>
<td align="right">-402.675</td>
<td align="right">-402.675</td>
<td align="right">-402.675</td>
<td align="right">-402.675</td>
</tr>
<tr class="even">
<td align="left">func. eval. nb.</td>
<td align="right">28.000</td>
<td align="right">28.000</td>
<td align="right">28.000</td>
<td align="right">28.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="left">grad. eval. nb.</td>
<td align="right">1.000</td>
<td align="right">1.000</td>
<td align="right">1.000</td>
<td align="right">1.000</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">time (sec)</td>
<td align="right">0.009</td>
<td align="right">0.002</td>
<td align="right">0.002</td>
<td align="right">0.001</td>
<td align="right">0.002</td>
<td align="right">0.003</td>
<td align="right">0.003</td>
<td align="right">0.002</td>
<td align="right">0.003</td>
</tr>
<tr class="odd">
<td align="left">fitted prob</td>
<td align="right">0.775</td>
<td align="right">0.775</td>
<td align="right">0.775</td>
<td align="right">0.775</td>
<td align="right">0.775</td>
<td align="right">0.775</td>
<td align="right">0.775</td>
<td align="right">0.775</td>
<td align="right">0.775</td>
</tr>
</tbody>
</table>
<table class="table">
<caption>Exponential trick optimization with approximated
gradient</caption>
<thead><tr class="header">
<th align="left"></th>
<th align="right">BFGS</th>
<th align="right">NM</th>
<th align="right">CGFR</th>
<th align="right">CGPR</th>
<th align="right">CGBS</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">fitted size</td>
<td align="right">57.335</td>
<td align="right">62.320</td>
<td align="right">58.595</td>
<td align="right">60.138</td>
<td align="right">60.875</td>
</tr>
<tr class="even">
<td align="left">fitted prob</td>
<td align="right">0.943</td>
<td align="right">0.948</td>
<td align="right">0.945</td>
<td align="right">0.946</td>
<td align="right">0.947</td>
</tr>
<tr class="odd">
<td align="left">fitted loglik</td>
<td align="right">-402.675</td>
<td align="right">-402.674</td>
<td align="right">-402.675</td>
<td align="right">-402.674</td>
<td align="right">-402.674</td>
</tr>
<tr class="even">
<td align="left">func. eval. nb.</td>
<td align="right">3.000</td>
<td align="right">45.000</td>
<td align="right">2501.000</td>
<td align="right">2276.000</td>
<td align="right">2272.000</td>
</tr>
<tr class="odd">
<td align="left">grad. eval. nb.</td>
<td align="right">1.000</td>
<td align="right">NA</td>
<td align="right">1001.000</td>
<td align="right">1001.000</td>
<td align="right">1001.000</td>
</tr>
<tr class="even">
<td align="left">time (sec)</td>
<td align="right">0.005</td>
<td align="right">0.003</td>
<td align="right">0.275</td>
<td align="right">0.267</td>
<td align="right">0.268</td>
</tr>
</tbody>
</table>
<table class="table">
<caption>Exponential trick optimization with true gradient</caption>
<thead><tr class="header">
<th align="left"></th>
<th align="right">G-BFGS</th>
<th align="right">G-CGFR</th>
<th align="right">G-CGPR</th>
<th align="right">G-CGBS</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">fitted size</td>
<td align="right">57.333</td>
<td align="right">57.333</td>
<td align="right">57.333</td>
<td align="right">57.333</td>
</tr>
<tr class="even">
<td align="left">fitted prob</td>
<td align="right">0.943</td>
<td align="right">0.943</td>
<td align="right">0.943</td>
<td align="right">0.943</td>
</tr>
<tr class="odd">
<td align="left">fitted loglik</td>
<td align="right">-402.675</td>
<td align="right">-402.675</td>
<td align="right">-402.675</td>
<td align="right">-402.675</td>
</tr>
<tr class="even">
<td align="left">func. eval. nb.</td>
<td align="right">18.000</td>
<td align="right">44.000</td>
<td align="right">39.000</td>
<td align="right">39.000</td>
</tr>
<tr class="odd">
<td align="left">grad. eval. nb.</td>
<td align="right">1.000</td>
<td align="right">3.000</td>
<td align="right">3.000</td>
<td align="right">3.000</td>
</tr>
<tr class="even">
<td align="left">time (sec)</td>
<td align="right">0.007</td>
<td align="right">0.002</td>
<td align="right">0.002</td>
<td align="right">0.002</td>
</tr>
</tbody>
</table>
<p>Using <code>llsurface</code>, we plot the log-likehood surface around
the true value (green) and the fitted parameters (red).</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/logLik-surface.html">llsurface</a></span><span class="op">(</span>min.arg <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">0.3</span><span class="op">)</span>, max.arg <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">15</span>, <span class="fl">1</span><span class="op">)</span>, xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">15</span><span class="op">)</span>,</span>
<span>          plot.arg <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"size"</span>, <span class="st">"prob"</span><span class="op">)</span>, nlev <span class="op">=</span> <span class="fl">25</span>,</span>
<span>          lseq <span class="op">=</span> <span class="fl">50</span>, data <span class="op">=</span> <span class="va">x</span>, distr <span class="op">=</span> <span class="st">"nbinom"</span>, back.col <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html" class="external-link">points</a></span><span class="op">(</span><span class="va">unconstropt</span><span class="op">[</span><span class="st">"fitted size"</span>, <span class="st">"BFGS"</span><span class="op">]</span>, <span class="va">unconstropt</span><span class="op">[</span><span class="st">"fitted prob"</span>, <span class="st">"BFGS"</span><span class="op">]</span>, </span>
<span>       pch <span class="op">=</span> <span class="st">"+"</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html" class="external-link">points</a></span><span class="op">(</span><span class="va">trueval</span><span class="op">[</span><span class="st">"size"</span><span class="op">]</span>, <span class="va">trueval</span><span class="op">[</span><span class="st">"prob"</span><span class="op">]</span>, pch <span class="op">=</span> <span class="st">"x"</span>, col <span class="op">=</span> <span class="st">"green"</span><span class="op">)</span></span></code></pre></div>
<p><img src="Optimalgo_files/figure-html/unnamed-chunk-22-1.png" class="r-plt" width="384"></p>
<p>We can simulate bootstrap replicates using the <code>bootdist</code>
function.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">b1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bootdist.html">bootdist</a></span><span class="op">(</span><span class="fu"><a href="../reference/fitdist.html">fitdist</a></span><span class="op">(</span><span class="va">x</span>, <span class="st">"nbinom"</span>, method <span class="op">=</span> <span class="st">"mle"</span>, optim.method <span class="op">=</span> <span class="st">"BFGS"</span><span class="op">)</span>, </span>
<span>               niter <span class="op">=</span> <span class="fl">100</span>, parallel <span class="op">=</span> <span class="st">"snow"</span>, ncpus <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">b1</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Parametric bootstrap medians and 95% percentile CI </span></span>
<span><span class="co">##      Median  2.5% 97.5%</span></span>
<span><span class="co">## size  57.33 57.33 57.33</span></span>
<span><span class="co">## mu     3.46  3.24  3.72</span></span></code></pre>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">b1</span>, trueval<span class="op">=</span><span class="va">trueval</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"size"</span>, <span class="st">"mu"</span><span class="op">)</span><span class="op">]</span><span class="op">)</span> </span></code></pre></div>
<p><img src="Optimalgo_files/figure-html/unnamed-chunk-23-1.png" class="r-plt" width="384"></p>
</div>
</div>
<div class="section level2">
<h2 id="conclusion">4. Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h2>
<p>Based on the two previous examples, we observe that all methods
converge to the same point. This is reassuring.<br>
However, the number of function evaluations (and the gradient
evaluations) is very different from a method to another. Furthermore,
specifying the true gradient of the log-likelihood does not help at all
the fitting procedure and generally slows down the convergence.
Generally, the best method is the standard BFGS method or the BFGS
method with the exponential transformation of the parameters. Since the
exponential function is differentiable, the asymptotic properties are
still preserved (by the Delta method) but for finite-sample this may
produce a small bias.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://lbbe.univ-lyon1.fr/fr/annuaires-des-membres/delignette-muller-marie-laure" class="external-link">Marie-Laure Delignette-Muller</a>, <a href="http://dutangc.free.fr" class="external-link">Christophe Dutang</a>, <a href="https://lbbe.univ-lyon1.fr/fr/annuaires-des-membres/siberchicot-aurelie" class="external-link">Aurélie Siberchicot</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
